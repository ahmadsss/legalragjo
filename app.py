import streamlit as st
import openai
import weaviate
from dotenv import load_dotenv
import os
from weaviate.classes.init import Auth

# Load .env (optional for local dev)
load_dotenv()

# Load secrets from Streamlit Cloud
openai.api_key = st.secrets["OPENAI_API_KEY"]
WEAVIATE_API_KEY = st.secrets["WEAVIATE_API_KEY"]
WEAVIATE_URL = st.secrets["WEAVIATE_URL"]

# Connect to Weaviate Cloud
client = weaviate.connect_to_weaviate_cloud(
    cluster_url=WEAVIATE_URL,
    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),
)

# ğŸ” Embed query using OpenAI
def embed_query(text):
    response = openai.embeddings.create(
        input=text,
        model="text-embedding-3-large"
    )
    return response.data[0].embedding

# ğŸ” Semantic retrieval from Weaviate
def retrieve_articles(query, limit=5):
    vector = embed_query(query)
    results = client.collections.get("LawArticle").query.near_vector(
        near_vector=vector,
        limit=limit
    )
    return results.objects

# ğŸ§  Generate a legal-style answer using GPT-4-turbo
def generate_answer(question, context):
    context_text = "\n\n".join(
        f"Ø§Ù„Ù…Ø§Ø¯Ø© {o.properties.get('article_number', '')}: {o.properties.get('article_title', '')}\n{o.properties.get('text', '')}"
        for o in context
    )

    prompt = #f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø°ÙƒÙŠ. Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ ÙÙ‚Ø· Ø¥Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ø£Ø¬Ø¨ Ø¹Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø¯Ù‚Ø© ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø¨Ø³Ø·.
# Ø¥Ø°Ø§ ÙˆØ±Ø¯Øª Ù…Ø§Ø¯Ø© ØªØ´ÙŠØ± Ø¥Ù„Ù‰ ØªØ¹Ø¯ÙŠÙ„ Ù…Ø§Ø¯Ø© Ø£Ø®Ø±Ù‰ (Ù…Ø«Ù„: "ÙŠÙ„ØºÙ‰ Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø© ÙƒØ°Ø§ ÙˆÙŠØ³ØªØ¹Ø§Ø¶ Ø¹Ù†Ù‡")ØŒ ÙØ§ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù‡Ùˆ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ÙØ¹Ù„ÙŠ. ÙˆØ¶Ù‘Ø­ Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ø¯Ù„ ÙˆØ§Ù„Ù‚Ø¯ÙŠÙ… Ø¥Ù† ÙˆØ¬Ø¯.

# Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©ØŒ ÙˆÙ„Ø§ ØªØ°ÙƒØ± Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ Ø£Ùˆ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø°ÙƒÙˆØ±Ø© Ø¨ÙˆØ¶ÙˆØ­.

# Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©:
f"""
{context_text}

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"""
    completion = openai.chat.completions.create(
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": "Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø©."},
            {"role": "user", "content": prompt}
        ]
    )
    return completion.choices[0].message.content.strip()

# ğŸŒ Streamlit Web UI
st.set_page_config(layout="centered", page_title="Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø°ÙƒÙŠ")
st.markdown("<h1 style='text-align: right; direction: rtl;'>ğŸ’¼ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠ</h1>", unsafe_allow_html=True)

question = st.text_input("âœï¸ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù‡Ù†Ø§:", key="query", placeholder="Ù…Ø§ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø°ÙŠ Ø¬Ø±Ù‰ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø§Ø¯Ø© 8ØŸ")

if question:
    with st.spinner("ğŸ” ÙŠØªÙ… Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©..."):
        articles = retrieve_articles(question)

    if not articles:
        st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ§Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.")
    else:
        with st.spinner("ğŸ¤– ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©..."):
            answer = generate_answer(question, articles)
        st.markdown("### ğŸ§  Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©", unsafe_allow_html=True)
        st.success(answer)

        with st.expander("ğŸ“œ Ø¹Ø±Ø¶ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©"):
            for obj in articles:
                st.markdown(f"**Ø§Ù„Ù…Ø§Ø¯Ø© {obj.properties.get('article_number')}** - {obj.properties.get('article_title')}", unsafe_allow_html=True)
                st.text(obj.properties.get("text"))
